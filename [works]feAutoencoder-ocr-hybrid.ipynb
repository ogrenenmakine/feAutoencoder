{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon as g\n",
    "from mxnet import nd\n",
    "import numpy as np\n",
    "from mxnet import autograd as ag\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 96\n",
    "height = 32\n",
    "width = 7*height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = mx.io.ImageRecordIter(path_imgrec=os.path.join('dataset','train.rec'), data_shape=(3,height,width),\n",
    "                                           shuffle=True, mean_r=123.68, mean_g=116.28, mean_b=103.53,\n",
    "                                           std_r=58.395, std_g=57.12, std_b=57.375,\n",
    "                                           batch_size=batch_size)\n",
    "\n",
    "data_iter_val = mx.io.ImageRecordIter(path_imgrec=os.path.join('dataset','val.rec'), data_shape=(3,height,width),\n",
    "                                           shuffle=True, mean_r=123.68, mean_g=116.28, mean_b=103.53,\n",
    "                                           std_r=58.395, std_g=57.12, std_b=57.375,\n",
    "                                           batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(g.nn.Block):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        with self.name_scope():\n",
    "            self.encodercnn = g.nn.HybridSequential('encoder_cnn_')\n",
    "            with self.encodercnn.name_scope():\n",
    "                self.encodercnn.add(g.nn.Conv2D(64, 3, strides=1, padding=1, activation='relu'))\n",
    "                self.encodercnn.add(g.nn.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "                self.encodercnn.add(g.nn.Conv2D(128, 3, strides=1, padding=1,activation='relu'))\n",
    "                self.encodercnn.add(g.nn.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "                self.encodercnn.add(g.nn.Conv2D(256, 3, strides=1, padding=1,activation='relu'))\n",
    "                self.encodercnn.add(g.nn.Conv2D(256, 3, strides=1, padding=1,activation='relu'))\n",
    "                self.encodercnn.add(g.nn.MaxPool2D(pool_size=(2,1), strides=(2,1)))\n",
    "                self.encodercnn.add(g.nn.Conv2D(512, 3, strides=1, padding=1))\n",
    "                self.encodercnn.add(g.nn.BatchNorm(axis=1, center=True, scale=True))\n",
    "                self.encodercnn.add(g.nn.Activation(activation='relu'))\n",
    "                self.encodercnn.add(g.nn.Conv2D(512, 3, strides=1, padding=1))\n",
    "                self.encodercnn.add(g.nn.BatchNorm(axis=1, center=True, scale=True))\n",
    "                self.encodercnn.add(g.nn.Activation(activation='relu'))\n",
    "                self.encodercnn.add(g.nn.MaxPool2D(pool_size=(2,1), strides=(2,1)))\n",
    "                self.encodercnn.add(g.nn.Conv2D(512, 1, strides=1, padding=0,activation='relu'))\n",
    "                \n",
    "            self.encoderrnn = g.rnn.SequentialRNNCell('encoder_rnn_')\n",
    "            with self.encoderrnn.name_scope():\n",
    "                self.encoderrnn.add(g.rnn.LSTMCell(512))\n",
    "                self.encoderrnn.add(g.rnn.LSTMCell(512))\n",
    "                #self.encoderrnn.add(g.rnn.LSTMCell(512))\n",
    "            \n",
    "            #self.intermediate_nn = g.nn.Dense(512)\n",
    "            \n",
    "            self.decoderrnn = g.rnn.SequentialRNNCell('decoder_rnn_')\n",
    "            with self.decoderrnn.name_scope():\n",
    "                self.decoderrnn.add(g.rnn.LSTMCell(512))\n",
    "                self.decoderrnn.add(g.rnn.LSTMCell(512))\n",
    "                #self.decoderrnn.add(g.rnn.LSTMCell(512))\n",
    "            \n",
    "            self.decodercnn = g.nn.HybridSequential('decoder_cnn_')\n",
    "            with self.decodercnn.name_scope():\n",
    "                self.decodercnn.add(g.nn.Conv2DTranspose(512, 1, strides=1, padding=0,activation='relu'))\n",
    "                # upsampling\n",
    "                self.decodercnn.add(g.nn.Conv2DTranspose(512, 3, strides=1, padding=1, activation='relu'))\n",
    "                self.decodercnn.add(g.nn.Conv2DTranspose(512, 3, strides=1, padding=1, activation='relu'))\n",
    "                # upsampling\n",
    "                self.decodercnn.add(g.nn.Conv2DTranspose(256, 3, strides=1, padding=1,activation='relu'))\n",
    "                self.decodercnn.add(g.nn.Conv2DTranspose(256, 3, strides=1, padding=1,activation='relu'))\n",
    "                # upsampling\n",
    "                self.decodercnn.add(g.nn.Conv2DTranspose(128, 3, strides=1, padding=1,activation='relu'))\n",
    "                # upsampling\n",
    "                self.decodercnn.add(g.nn.Conv2DTranspose(64, 3, strides=1, padding=1, activation='relu'))\n",
    "                # upsampling\n",
    "                self.decodercnn.add(g.nn.Conv2DTranspose(3, 3, strides=1, padding=1, activation='tanh'))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # encoder cnn\n",
    "        x = self.encodercnn(x)\n",
    "        \n",
    "        # encoder rnn\n",
    "        status = self.encoderrnn.begin_state(batch_size=batch_size,ctx=ctx)\n",
    "        for i in range(x.shape[3]):\n",
    "            cvector, status = self.encoderrnn(nd.flatten(x[:,:,:,i]), status)\n",
    "            if i == 0:\n",
    "                outputs_o = mx.nd.expand_dims(cvector, axis=2)\n",
    "            else:\n",
    "                outputs_o = mx.nd.concat(outputs_o,mx.nd.expand_dims(cvector,axis=2),dim=2)\n",
    "        #cvector = self.intermediate_nn(cvector)\n",
    "        \n",
    "        # decoder rnn\n",
    "        status = self.decoderrnn.begin_state(batch_size=batch_size,ctx=ctx)\n",
    "        for i in range(x.shape[3]):\n",
    "            cvector, status = self.decoderrnn(nd.flatten(mx.nd.concat(cvector,outputs_o[:,:,i])), status)\n",
    "            if i == 0:\n",
    "                outputs = mx.nd.expand_dims(cvector, axis=2)\n",
    "            else:\n",
    "                outputs = mx.nd.concat(outputs,mx.nd.expand_dims(cvector,axis=2),dim=2)\n",
    "        xs = mx.nd.Reshape(outputs,(x.shape[0],x.shape[1],1,x.shape[3]))\n",
    "        \n",
    "        # decoder cnn\n",
    "        for i in range(len(self.decodercnn)):\n",
    "            xs = self.decodercnn[i](xs)\n",
    "            if (i == 0):\n",
    "                xs = mx.nd.contrib.BilinearResize2D(xs, height=4, width=56)\n",
    "            elif (i == 2):\n",
    "                xs = mx.nd.contrib.BilinearResize2D(xs, height=8, width=56)\n",
    "            elif (i == 4):\n",
    "                xs = mx.nd.contrib.BilinearResize2D(xs, height=16, width=112)\n",
    "            elif (i == 5):\n",
    "                xs = mx.nd.contrib.BilinearResize2D(xs, height=32, width=224)\n",
    "        return xs*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder()\n",
    "model.hybridize()\n",
    "model.collect_params().initialize(mx.init.Xavier(magnitude=2), ctx=ctx)\n",
    "for batch in data_iter:\n",
    "    batch\n",
    "    break\n",
    "print(model(batch.data[0].as_in_context(ctx)).shape)\n",
    "model.save_parameters(\"process/ae_*.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = g.loss.L2Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metric = mx.metric.MAE()\n",
    "val_metric = mx.metric.MAE()\n",
    "#for opt in sorted({'Adam','RMSProp','SGD'}):\n",
    "for opt in sorted({'Adam'}):\n",
    "#    for lr in sorted({0.1,0.01,0.001},reverse=True):\n",
    "    for lr in sorted({0.001},reverse=True):\n",
    "        start_epoch = 0\n",
    "        epochs = 3\n",
    "        model.load_parameters(\"process/ae_*.params\")\n",
    "        optimizer = g.Trainer(model.collect_params(), opt, {'learning_rate': lr, 'wd': 1e-5})\n",
    "        print('### Optimizer: %s ### Learning Rate: %.3f' % (opt,lr))\n",
    "        val_val_check = np.inf\n",
    "        for epoch in range(start_epoch, epochs):\n",
    "            # train\n",
    "            train_loss = 0\n",
    "            train_metric.reset()\n",
    "            data_iter.reset()\n",
    "            tic = time.time()\n",
    "            counter = 0\n",
    "            for batch in data_iter:\n",
    "                with ag.record():\n",
    "                    x = batch.data[0].as_in_context(ctx)\n",
    "                    y = model(x)\n",
    "                    loss = criterion(x,y)\n",
    "                    loss.backward()\n",
    "                    train_loss += mx.nd.sum(loss).asscalar()\n",
    "                optimizer.step(batch_size, ignore_stale_grad=True)\n",
    "                train_metric.update(x, y)\n",
    "                counter += 1\n",
    "            toc = time.time()\n",
    "            name_train, val_train = train_metric.get()\n",
    "            # validation\n",
    "            val_loss = 0\n",
    "            val_metric.reset()\n",
    "            data_iter_val.reset()\n",
    "            for batch in data_iter_val:\n",
    "                x = batch.data[0].as_in_context(ctx)\n",
    "                y = model(x)\n",
    "                loss = criterion(x,y)\n",
    "                val_loss += mx.nd.sum(loss).asscalar()\n",
    "                val_metric.update(x, y)\n",
    "            name_val, val_val = val_metric.get()\n",
    "            print('epoch:%3d;\\t train:%.6e;%.6e;val:%.6e;%.6e;\\t Speed:%d'\n",
    "                  %(epoch, train_loss/(counter*batch_size), val_train, val_loss/(counter*batch_size), val_val, (counter*batch_size)/(toc-tic)))\n",
    "            if val_val < val_val_check:\n",
    "                model.save_parameters('process/ae_*.params')\n",
    "                val_val_check = val_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_parameters(\"process/ae_*.params\")\n",
    "for batch in data_iter:\n",
    "    x = batch.data[0].as_in_context(ctx)\n",
    "    y = model(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "whichIm = randint(0,batch_size)\n",
    "val_image = y[whichIm,:,:,:].as_in_context(mx.cpu())\n",
    "val_image = val_image.transpose((1, 2, 0)) * nd.array((0.229, 0.224, 0.225)) + nd.array((0.485, 0.456, 0.406))\n",
    "val_image = (val_image * 255).clip(0, 255)\n",
    "val_image = val_image.asnumpy()\n",
    "val_image = val_image.astype(np.uint8)\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.imshow(val_image)\n",
    "plt.savefig('/home/mcy/Dropbox/val.png')\n",
    "plt.show()\n",
    "org = x[whichIm,:,:,:].as_in_context(mx.cpu())\n",
    "org = org.transpose((1, 2, 0)) * nd.array((0.229, 0.224, 0.225)) + nd.array((0.485, 0.456, 0.406))\n",
    "org = (org * 255).clip(0, 255)\n",
    "org = org.asnumpy()\n",
    "org = org.astype(np.uint8)\n",
    "plt.imshow(org)\n",
    "plt.savefig('/home/mcy/Dropbox/org.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
