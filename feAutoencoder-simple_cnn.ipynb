{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon as g\n",
    "from mxnet import nd\n",
    "import numpy as np\n",
    "from mxnet import autograd as ag\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "height = 16\n",
    "width = 7*height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = mx.io.ImageRecordIter(path_imgrec=os.path.join('dataset','train.rec'), data_shape=(3,height,width),\n",
    "                                           shuffle=True, mean_r=123.68, mean_g=116.28, mean_b=103.53,\n",
    "                                           std_r=58.395, std_g=57.12, std_b=57.375,\n",
    "                                           batch_size=batch_size)\n",
    "\n",
    "data_iter_val = mx.io.ImageRecordIter(path_imgrec=os.path.join('dataset','val.rec'), data_shape=(3,height,width),\n",
    "                                           shuffle=True, mean_r=123.68, mean_g=116.28, mean_b=103.53,\n",
    "                                           std_r=58.395, std_g=57.12, std_b=57.375,\n",
    "                                           batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(g.nn.HybridBlock):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        with self.name_scope():\n",
    "            self.encoder = g.nn.HybridSequential('encoder_')\n",
    "            with self.encoder.name_scope():\n",
    "                self.encoder.add(g.nn.Conv2D(32, 3, padding=1, activation='relu'))\n",
    "                self.encoder.add(g.nn.MaxPool2D(2, 2))\n",
    "                self.encoder.add(g.nn.Conv2D(32, 3, padding=1, activation='relu'))\n",
    "                self.encoder.add(g.nn.MaxPool2D(2, 2))\n",
    "\n",
    "            self.decoder = g.nn.HybridSequential('decoder_')\n",
    "            with self.decoder.name_scope():\n",
    "                self.decoder.add(g.nn.Conv2D(32, 3, padding=1, activation='relu'))\n",
    "                self.decoder.add(g.nn.Conv2D(32, 3, padding=1, activation='relu'))\n",
    "                self.decoder.add(g.nn.Conv2D(3, 3,  padding=1,  activation='tanh'))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        for i in range(len(self.decoder)):\n",
    "            x = self.decoder[i](x)\n",
    "            if i < 2:\n",
    "                x = mx.nd.UpSampling(x,scale=2,sample_type='nearest')\n",
    "        return x*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder()\n",
    "model.hybridize()\n",
    "model.collect_params().initialize(mx.init.Xavier(magnitude=2), ctx=ctx)\n",
    "for batch in data_iter:\n",
    "    batch\n",
    "    break\n",
    "print(model(batch.data[0].as_in_context(ctx)).shape)\n",
    "model.save_parameters(\"ae_init.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = g.loss.L2Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_metric = mx.metric.MAE()\n",
    "val_metric = mx.metric.MAE()\n",
    "#for opt in sorted({'Adam','RMSProp','SGD'}):\n",
    "for opt in sorted({'SGD'}):\n",
    "#    for lr in sorted({0.1,0.01,0.001},reverse=True):\n",
    "    for lr in sorted({0.1},reverse=True):\n",
    "        start_epoch = 0\n",
    "        epochs = 100\n",
    "        model.load_parameters(\"ae_init.params\")\n",
    "        optimizer = g.Trainer(model.collect_params(), opt, {'learning_rate': lr, 'wd': 1e-5})\n",
    "        print('### Optimizer: %s ### Learning Rate: %.3f' % (opt,lr))\n",
    "        for epoch in range(start_epoch, epochs):\n",
    "            # train\n",
    "            train_loss = 0\n",
    "            train_metric.reset()\n",
    "            data_iter.reset()\n",
    "            tic = time.time()\n",
    "            counter = 0\n",
    "            for batch in data_iter:\n",
    "                with ag.record():\n",
    "                    x = batch.data[0].as_in_context(ctx)\n",
    "                    y = model(x)\n",
    "                    loss = criterion(x,y)\n",
    "                    loss.backward()\n",
    "                    train_loss += mx.nd.sum(loss).asscalar()\n",
    "                optimizer.step(batch_size, ignore_stale_grad=True)\n",
    "                train_metric.update(x, y)\n",
    "                counter += 1\n",
    "            toc = time.time()\n",
    "            name_train, val_train = train_metric.get()\n",
    "            # validation\n",
    "            val_loss = 0\n",
    "            val_metric.reset()\n",
    "            data_iter_val.reset()\n",
    "            for batch in data_iter_val:\n",
    "                x = batch.data[0].as_in_context(ctx)\n",
    "                y = model(x)\n",
    "                loss = criterion(x,y)\n",
    "                val_loss += mx.nd.sum(loss).asscalar()\n",
    "                val_metric.update(x, y)\n",
    "            name_val, val_val = val_metric.get()\n",
    "            print('epoch:%3d;\\t train:%.6e;%.6e;val:%.6e;%.6e;\\t Speed:%d'\n",
    "                  %(epoch, train_loss/(counter*batch_size), val_train, val_loss/(counter*batch_size), val_val, (counter*batch_size)/(toc-tic)))\n",
    "            model.save_parameters('process/ae_%s_%.3f_%d.params' % (opt, lr, epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in data_iter_val:\n",
    "    x = batch.data[0].as_in_context(ctx)\n",
    "    y = model(x)\n",
    "    val_image = y[0,:,:,:].as_in_context(mx.cpu())\n",
    "    val_image = val_image.transpose((1, 2, 0)) * nd.array((0.229, 0.224, 0.225)) + nd.array((0.485, 0.456, 0.406))\n",
    "    val_image = (val_image * 255).clip(0, 255)\n",
    "    val_image = val_image.asnumpy()\n",
    "    val_image = val_image.astype(np.uint8)\n",
    "    plt.imshow(val_image)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
